{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yt916O_HhkAy"
   },
   "source": [
    "# Part 1: Imports, data uploads and preparation.\n",
    "\n",
    "As is customary, let us first call the Python libraries needed here, and upload the needed data and code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 564,
     "status": "ok",
     "timestamp": 1712936927047,
     "user": {
      "displayName": "Charles Rougé",
      "userId": "02328605607346880259"
     },
     "user_tz": -60
    },
    "id": "hoEWhFzkXIIb"
   },
   "outputs": [],
   "source": [
    "from model import setup, balance_calcs, func_FDC, visuals, performance\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WMIgClwijXD_"
   },
   "source": [
    "## Loading model and water balance for historical data\n",
    "\n",
    "In this tutorial we will compute performance, then compare it for the scenarios defined in Tutorial 3. First let's compute the historical water balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3136,
     "status": "ok",
     "timestamp": 1712936952869,
     "user": {
      "displayName": "Charles Rougé",
      "userId": "02328605607346880259"
     },
     "user_tz": -60
    },
    "id": "OA_TBdm4rxcW",
    "outputId": "35a6129e-9086-444e-a7b9-271367b2dc63"
   },
   "outputs": [],
   "source": [
    "# Preparing the model\n",
    "reservoir_name = 'Conowingo'\n",
    "downstream_demand_names = ['Environmental']\n",
    "direct_demand_names = ['Baltimore', 'Chester', 'Nuclear plant']\n",
    "\n",
    "# Loading the model!\n",
    "conowingo = setup.define_reservoir(reservoir_name, downstream_demand_names, direct_demand_names)\n",
    "\n",
    "# Read flow and demand data. We keep this copy of the data for the simulation of different futures.\n",
    "flows_default = setup.extract_flows(reservoir=conowingo)\n",
    "display(flows_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7938,
     "status": "ok",
     "timestamp": 1712937043084,
     "user": {
      "displayName": "Charles Rougé",
      "userId": "02328605607346880259"
     },
     "user_tz": -60
    },
    "id": "smixVwQqAMn2",
    "outputId": "7af7e4d3-10d8-435e-e12c-9b3dcfab3df7"
   },
   "outputs": [],
   "source": [
    "# First, make a copy of the flows to initialise the water balance\n",
    "historical_balance = flows_default.copy()  # Keep flows_default as an untouched copy\n",
    "\n",
    "# Computing the water balance for our standard operating policy (SOP)\n",
    "balance_calcs.sop_full(reservoir=conowingo, water_flows=historical_balance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H9-n677W4eom"
   },
   "source": [
    "# Part 2: performance metrics\n",
    "\n",
    "Management objectives are as follows:\n",
    "1) Produce hydropower\n",
    "2) Meet environmental flows\n",
    "3) Meet domestic and industrial demands\n",
    "4) Avoid excessive flooding that would require evacuating the downstream town of “Port Deposit” (15,000 m3/s)\n",
    "5) Maintain a water level compatible with recreation (hydraulic head over 106.5 ft, where 1ft = 0.3048 m) in June, July and August.\n",
    "\n",
    "First, we will explore objective (1), and we will then focus on the other objectives. For these objectives, we will compare the water flows / levels versus a threshold, and use the R-R-V indicators defined in the lecture (reliability / resilience / vulnerability).\n",
    "\n",
    "\n",
    "## 2.1 - Hydropower\n",
    "\n",
    "For Conowingo Dam, key parameters of the hydropower plant can be found in the **\"Reservoir characteristics\"** part of the spreadsheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we download the key data\n",
    "key_parameters = pd.read_excel('data/Conowingo_data.xlsx', sheet_name='Reservoir characteristics')\n",
    "\n",
    "# We define the hydropower station parameters\n",
    "installed_capacity = key_parameters.iloc[4, 1]\n",
    "nominal_head = key_parameters.iloc[3, 1]\n",
    "max_release = key_parameters.iloc[5, 1]\n",
    "\n",
    "# Variables\n",
    "rho = 1000 # Density of water, kg/m3\n",
    "g = 9.81 # Acceleration of gravity, m/s2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can use the equation given in the lecture, linking hydropower station parameters to power production, to deduce the combined efficiency of converting potential energy into kinetic energy (through the turbine) and of converting this kinetic energy to electricity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deduce efficiency\n",
    "efficiency = installed_capacity*1E6 / (rho*g*nominal_head*max_release)\n",
    "print(\"Turbines and plant combined efficiency is \" + \"{:.3f}\".format(efficiency))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these parameters and the water balance, we can get time series of daily hydropower production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get hydropower production time series\n",
    "\n",
    "n_steps = len(historical_balance)\n",
    "\n",
    "# Get release time series (capped by max release)\n",
    "release = np.minimum(historical_balance['Outflows (m3/s)'].values, np.ones(n_steps)*max_release)\n",
    "\n",
    "# Get hydraulic head time series\n",
    "hy_head = np.zeros(n_steps)\n",
    "for t in range(n_steps):\n",
    "  depth = conowingo.get_height(historical_balance.iloc[t, -1])\n",
    "  hy_head[t] = nominal_head - conowingo.total_lake_depth + depth\n",
    "\n",
    "# Deduce daily hydropower production time series (in MWh)\n",
    "hydropower_daily = pd.Series(index=historical_balance.index, data=rho*g*efficiency*np.multiply(hy_head, release)*24/1E6, name='Daily hydropower production (MWh)')\n",
    "\n",
    "plt.plot(hydropower_daily.index, hydropower_daily/1000)\n",
    "plt.xlabel('Year', size=14)\n",
    "plt.ylabel('Daily hydropower production (GWh)', size=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not a very helpful visual, and aggregation to annual data will certainly be helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us get annual hydropower production\n",
    "\n",
    "# First the headline number: average over 70 years (GWh)\n",
    "print('Annual average hydropower production at Conowingo is ' + \"{:.0f}\".format(hydropower_daily.sum() / 70 / 1000) + ' GWh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the time series\n",
    "hydropower_annual = hydropower_daily.resample('YE').sum()/1000\n",
    "hydropower_annual.name = 'Annual hydropower production (GWh)'\n",
    "\n",
    "print('Check we have the same average. \\nAnnual average hydropower production at Conowingo is ' + \"{:.0f}\".format(hydropower_annual.mean()) + ' GWh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us plot it\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.plot(hydropower_annual.index.year, hydropower_annual, c='b', label='No intake')\n",
    "ax.set_xlabel('Date', size=14)\n",
    "ax.set_ylabel('Annual power production (GWh)', size=14)\n",
    "\n",
    "# We set the boundaries of the x-axis\n",
    "ax.set_xlim(hydropower_annual.index.year[0], hydropower_annual.index.year[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us compare with annual average flows.\n",
    "fig = visuals.annual_average(daily_data=pd.Series(historical_balance['Total inflows (m3/s)']) * 86400/1E9, \n",
    "                             data_label='total inflow ($km^3$)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1. What can we say about the correlation between inflows and hydropower production?**\n",
    "\n",
    "\n",
    "## 2.2 - R-R-V indicators\n",
    "\n",
    "Let us now introduce a function to compute the R-R-V performance metrics introduced in the lecture.\n",
    "\n",
    "**Question 2. In the function below, do you recognise the formulas given in the lecture? What are extra steps that need to be taken? And why do we measure vulnerability as percentage?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "aborted",
     "timestamp": 1712936953207,
     "user": {
      "displayName": "Charles Rougé",
      "userId": "02328605607346880259"
     },
     "user_tz": -60
    },
    "id": "U1l9SaSY4mRN"
   },
   "outputs": [],
   "source": [
    "def rrv_indicators(time_series, dynamic_threshold, above_desirable, name, **kwargs):\n",
    "    \"\"\"\n",
    "    Compute the RRV indicators for a time series vs. a threshold. Arguments:\n",
    "        time_series: numpy vector\n",
    "        dynamic_threshold: numpy vectors of same length as `time_series`\n",
    "        above_desirable: boolean. If True we value staying at or above a threshold.\n",
    "        name: String, the name of the site\n",
    "        optional argument `vul_unit`: String, default as a percentage, to specify how vulnerability is evaluated\n",
    "    Returns a pandas DataFrame with several perf_metrics metrics.\n",
    "    \"\"\"\n",
    "\n",
    "    # Optional argument\n",
    "    vul_unit = kwargs.pop(\"vul_unit\", '%')\n",
    "\n",
    "    # Local variables\n",
    "    n_steps = len(time_series)\n",
    "    tolerance = 1E-6  # for rounding errors\n",
    "\n",
    "    # If above_desirable is false we need to change sign of all data now, so we compare a and b\n",
    "    a = (2 * above_desirable - 1) * time_series\n",
    "    b = (2 * above_desirable - 1) * dynamic_threshold\n",
    "    b = b - tolerance\n",
    "\n",
    "    # Initialise output\n",
    "    indicators = pd.DataFrame(columns=['Name', 'Reliability (0-1)', 'Resilience (-)', 'Vulnerability', 'Failure count'])\n",
    "    indicators.loc[0, 'Name'] = name\n",
    "\n",
    "    # Reliability\n",
    "    indicators.loc[0, 'Reliability (0-1)'] = 1 - np.sum(a < b) / n_steps\n",
    "\n",
    "    # We need to count failure events to compute resilience and vulnerability\n",
    "    event_count = 0\n",
    "    # We also need to have the maximal amplitude or magnitude of failure\n",
    "    magnitude = []\n",
    "    # We use a while loop to count events and their magnitude\n",
    "    t = 0\n",
    "    while t < n_steps:\n",
    "\n",
    "        if a[t] < b[t]:\n",
    "            # New event! we need to update the count of failure events\n",
    "            event_count = event_count + 1\n",
    "            # We also need to keep track of the maximum amplitude of failure\n",
    "            # By default failure is expressed in relative terms\n",
    "            if vul_unit == '%':\n",
    "                magnitude.append((b[t] - a[t]) / abs(b[t]))\n",
    "            else:\n",
    "                magnitude.append(b[t] - a[t])\n",
    "            # Now while event lasts\n",
    "            while a[t] < b[t]:\n",
    "                t = t+1\n",
    "                if t == n_steps:\n",
    "                    break\n",
    "                if vul_unit == '%':\n",
    "                    magnitude[-1] = max(magnitude[-1], (b[t] - a[t]) / abs(b[t]))\n",
    "                else:\n",
    "                    magnitude[-1] = max(magnitude[-1], b[t] - a[t])\n",
    "\n",
    "        # Time increment so while loop concludes\n",
    "        t = t+1\n",
    "\n",
    "    # Resilience\n",
    "    indicators.loc[0, 'Resilience (-)'] = event_count / (n_steps * (1 - indicators.loc[0, 'Reliability (0-1)']))\n",
    "\n",
    "    # Vulnerability (as a percentage)\n",
    "    if vul_unit == '%':\n",
    "        indicators.loc[0, 'Vulnerability'] = \"{:.0f}\".format(np.mean(magnitude) * 100) + '%'\n",
    "    else:\n",
    "        indicators.loc[0, 'Vulnerability'] = \"{:.2f}\".format(np.mean(magnitude)) + vul_unit\n",
    "\n",
    "    # Finally, exporting the failure count\n",
    "    indicators.loc[0, 'Failure count'] = event_count\n",
    "\n",
    "    return indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application to all four Conowingo demands\n",
    "metrics = pd.concat([rrv_indicators(historical_balance['Withdrawals Baltimore (m3/s)'].to_numpy(), \n",
    "                                    historical_balance['Baltimore demand (m3/s)'].to_numpy(), True, 'Baltimore'),\n",
    "                     rrv_indicators(historical_balance['Withdrawals Chester (m3/s)'].to_numpy(), \n",
    "                                    historical_balance['Chester demand (m3/s)'].to_numpy(), True, 'Chester'),\n",
    "                     rrv_indicators(historical_balance['Withdrawals Nuclear plant (m3/s)'].to_numpy(), \n",
    "                                    historical_balance['Nuclear plant demand (m3/s)'].to_numpy(), True, 'Nuclear'),\n",
    "                     rrv_indicators(historical_balance['Outflows (m3/s)'].to_numpy(), \n",
    "                                    historical_balance['Environmental demand (m3/s)'].to_numpy(), True, 'Env. flows')],\n",
    "                     axis=0, ignore_index=True)\n",
    "\n",
    "print('Performance metrics for demands are:\\n')\n",
    "display(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "aborted",
     "timestamp": 1712936953207,
     "user": {
      "displayName": "Charles Rougé",
      "userId": "02328605607346880259"
     },
     "user_tz": -60
    },
    "id": "mlQNVU-zZnRs"
   },
   "outputs": [],
   "source": [
    "# Same for flooding\n",
    "flooding_metrics = rrv_indicators(time_series=historical_balance['Outflows (m3/s)'].to_numpy(), \n",
    "                                  dynamic_threshold=15000*np.ones(len(historical_balance)), \n",
    "                                  above_desirable=False, \n",
    "                                  name='Flooding')\n",
    "\n",
    "metrics = pd.concat([metrics, flooding_metrics], axis=0, ignore_index=True)\n",
    "\n",
    "print('Performance metrics including demands and flooding are:\\n')\n",
    "display(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3. Compute how long it takes a flood at the flooding threshold to completely fill Conowingo, and use this to comment on the reliability, resilience and vulnerability for the flooding objective. In particular, can we use different operating policies to avoid flooding the town downstream of Conowingo (Port Deposit)?**\n",
    "\n",
    "We have now computed metrics for objectives (1) to (4) under historical flows and the standard operating policy (SOP). We now need to evaluate the last objective, summer recreation. The key difference is that the three over seasons (75% of time) don't count towards reliability calculations. This necessitates extra leg work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "aborted",
     "timestamp": 1712936953207,
     "user": {
      "displayName": "Charles Rougé",
      "userId": "02328605607346880259"
     },
     "user_tz": -60
    },
    "id": "Il7qi92hbARW"
   },
   "outputs": [],
   "source": [
    "# Summer recreation (lake levels need to stay above a certain level in June, July and August)\n",
    "\n",
    "# We need time series of level objectives. We initialise at 0 requirement.\n",
    "level_objective = pd.Series(index=historical_balance.index, data=np.zeros(len(historical_balance)))\n",
    "\n",
    "# We set a level during summer months, to be compared with lake level (which coincide with hydraulic head)\n",
    "summer_requirement = 106.5*0.3048\n",
    "for month in np.arange(6, 9, 1):\n",
    "    level_objective[level_objective.index.month == month] = summer_requirement\n",
    "\n",
    "# Get hydraulic head time series, assuming linear relationship between depth and lake area\n",
    "hydraulic_head = np.zeros(len(historical_balance))\n",
    "for t in range(len(historical_balance)):\n",
    "    depth = conowingo.get_height(historical_balance.iloc[t, -1])\n",
    "    hydraulic_head[t] = conowingo.hydropower_plant.nominal_head - conowingo.total_lake_depth + depth\n",
    "\n",
    "# Get the indicators\n",
    "recreation_metrics = rrv_indicators(hydraulic_head, level_objective.to_numpy(), True, 'Recreation', vul_unit='m')\n",
    "\n",
    "# We need to account for the fact that this requirement is for three months only, which impacts reliability\n",
    "# Failure happens more often if measured in the shorter time window\n",
    "recreation_metrics.iloc[0, 1] = 1 - (1-recreation_metrics.iloc[0, 1]) * len(level_objective) / (70*(30+31+31))\n",
    "\n",
    "metrics = pd.concat([metrics, recreation_metrics], axis=0, ignore_index=True)\n",
    "print('Performance metrics including demands, flooding and recreation are:\\n')\n",
    "display(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "aborted",
     "timestamp": 1712936953207,
     "user": {
      "displayName": "Charles Rougé",
      "userId": "02328605607346880259"
     },
     "user_tz": -60
    },
    "id": "-RU7JJ6fene2"
   },
   "outputs": [],
   "source": [
    "# Add a new column, volumetric reliability\n",
    "metrics.insert(5, 'Volumetric reliability', [0, 0, 0, 0, 'N/A', 'N/A'])\n",
    "display(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "aborted",
     "timestamp": 1712936953208,
     "user": {
      "displayName": "Charles Rougé",
      "userId": "02328605607346880259"
     },
     "user_tz": -60
    },
    "id": "zA_7wOTCggaT"
   },
   "outputs": [],
   "source": [
    "# Volumetric reliability is only defined for the demands, and it relies on the grand total supply / demand\n",
    "totals = historical_balance.sum(axis=0)\n",
    "\n",
    "metrics.loc[0, 'Volumetric reliability'] = totals['Withdrawals Baltimore (m3/s)'] / totals['Baltimore demand (m3/s)']\n",
    "metrics.loc[1, 'Volumetric reliability'] = totals['Withdrawals Chester (m3/s)'] / totals['Chester demand (m3/s)']\n",
    "metrics.loc[2, 'Volumetric reliability'] = totals['Withdrawals Nuclear plant (m3/s)'] / totals['Nuclear plant demand (m3/s)']\n",
    "metrics.loc[3, 'Volumetric reliability'] = np.sum(np.minimum(historical_balance['Environmental demand (m3/s)'], \n",
    "                                                             historical_balance['Outflows (m3/s)'])) / totals['Environmental demand (m3/s)']\n",
    "\n",
    "display(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4. Which objectives do you feel the chosen operating policy favours? Why?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: performance change with climate change\n",
    "\n",
    "Let us now examine how the climate changes modelled in Tutorial 3 might affect performance, compared with the historical balance. Recall the two models for streamflow change:\n",
    "1) Uniform decrease affecting all flows equally. As in tutorial 3 we assume a 20% decrease in flows.\n",
    "2) A model combining a 20% average decrease in inflows, with a 50% increase in variability and a 40% decrease in the first percentile of flows (low flows). In other words, the model represents an increase in both high and low flows.\n",
    "\n",
    "## 3.1 - Recall what these models look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Water balance for the uniform 20% decrease\n",
    "uniform_drier = balance_calcs.uniform_change_model(flows_default, 0.8)  # Initialise water balance\n",
    "balance_calcs.sop_full(conowingo, uniform_drier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Water balance for the 20% average decrease with amplified extremes\n",
    "mean_multiplier = 0.8\n",
    "variability_multiplier =1.5\n",
    "low_flow_multiplier = 0.6\n",
    "drier_more_extreme = balance_calcs.amplified_extremes_model(flows_default, [mean_multiplier, variability_multiplier, low_flow_multiplier], 1) \n",
    "balance_calcs.sop_full(conowingo, drier_more_extreme)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember the difference between the models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = visuals.compare_fdc(reference=pd.Series(historical_balance['Total inflows (m3/s)']), \n",
    "                          alternative=pd.Series(uniform_drier['Total inflows (m3/s)']), \n",
    "                          alternative_2=pd.Series(drier_more_extreme['Total inflows (m3/s)']), \n",
    "                          labels=['Historical', 'Drier future (uniform)', 'Drier and more extreme future'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And remember what that means for storage during a dry period. **What could that mean for performance?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = visuals.compare_storage_timeseries(reservoir=conowingo, \n",
    "                                         storage_1=pd.Series(historical_balance['Storage (m3)']),\n",
    "                                         storage_2=pd.Series(uniform_drier['Storage (m3)']), \n",
    "                                         storage_3=pd.Series(drier_more_extreme['Storage (m3)']),\n",
    "                                         labels=['Historical', 'Drier future (uniform)', 'Drier and more extreme future'],\n",
    "                                         first_date=datetime.date(1962, 1, 1), \n",
    "                                         last_date=datetime.date(1970, 1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 - Performance comparison\n",
    "\n",
    "All the performance code is also available in `model/performance.py` which can be imported using `from model import performance`.\n",
    "\n",
    "We display one above the other the full metrics for:\n",
    "1) Historical conditions.\n",
    "2) Model 1, uniform 20% inflow decrease.\n",
    "3) Model 2, 20% average inflow decrease with extreme amplification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(metrics)  # 1 - Historical conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_1 = performance.all_metrics(conowingo, uniform_drier)\n",
    "display(metrics_1)  # 2 - Model 1, uniform 20% inflow decrease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_2 = performance.all_metrics(conowingo, drier_more_extreme)\n",
    "display(metrics_2)  # 3 - Model 2, 20% average inflow decrease with extreme amplification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5. How did the choice of model affect performance?**\n",
    "\n",
    "**Question 6. Try changing parameters of statistical model. For instance, what happens to performance if instead of a 20% decrease, the mean were unchanged compared with historical conditions?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "civx782",
   "language": "python",
   "name": "civx782"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
